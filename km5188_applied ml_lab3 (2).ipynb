{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e55ea7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "iris_df = pd.read_csv(\"spambase.csv\")\n",
    "\n",
    "real_iris_df = pd.read_csv(\"iris.csv\", names=[\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\", \"class\"])\n",
    "real_iris_df = real_iris_df.replace({'Iris-setosa':0, 'Iris-versicolor': 1, 'Iris-virginica': 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80cdeba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spam = pd.read_csv(\"spambase.csv\")\n",
    "# len(spam.iloc[:,1])\n",
    "# len(np.unique(spam.iloc[:,1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff45c8b",
   "metadata": {},
   "source": [
    "# HELPER FUNCTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fae976d",
   "metadata": {},
   "source": [
    "## informational gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af87c1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def info_gain(dfp, df1, df2):\n",
    "    \n",
    "    \"\"\" returns an informational gain of a \"class\" column of given dataframse\n",
    "    \n",
    "    type dfp, df1, df2: pandas dataframes\n",
    "    \n",
    "    rtype: float\n",
    "    \n",
    "    \"\"\"\n",
    "    def entropy(y):\n",
    "        \"\"\" returns the entropy of values in the y\n",
    "    \n",
    "        type y: pandas df consisting of one column\n",
    "        rtype: float\n",
    "\n",
    "        \"\"\"\n",
    "        if y.empty:\n",
    "            return 0\n",
    "\n",
    "        els, counts = np.unique(y, return_counts=True)\n",
    "        \n",
    "        # if the set if homogeneous \n",
    "        if len(els) == 1:\n",
    "            return 0  # Entropy is zero if there's no variance\n",
    "        \n",
    "        probs = counts / len(y)\n",
    "        return -np.sum(probs * np.log2(probs))\n",
    "    \n",
    "    n, m1, m2 = len(dfp), len(df1), len(df2)\n",
    "    \n",
    "    if n == 0 or m1 == 0 or m2 == 0:\n",
    "        return 0\n",
    "    \n",
    "    internal_entropy = (entropy(df1.iloc[:,-1]) * m1 / n) + (entropy(df2.iloc[:,-1]) * m2 / n)\n",
    "    parent_entropy = entropy(dfp.iloc[:,-1])\n",
    "    \n",
    "    return parent_entropy - internal_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1db21d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing\n",
    "# y = [1,2,2,2,2,3,3,3]\n",
    "# els, counts = np.unique(y, return_counts=True)\n",
    "# print(els, counts)\n",
    "# probs = counts/len(y)\n",
    "# probs\n",
    "# np.sum(np.log2(probs)*probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b286eaf",
   "metadata": {},
   "source": [
    "## splitting the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f96dc3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_threshold(column, df):\n",
    "    \"\"\" iterates through all values in  column of df, \n",
    "    finds the best column, that splits with the most info gain\n",
    "    \n",
    "    type column: one column df \n",
    "    type df: a dataframe \n",
    "    \n",
    "    returns:\n",
    "    \n",
    "    best split value, corresponding info gain\n",
    "    rtype: (float, float) \n",
    "    \n",
    "    \"\"\"\n",
    "    best_split = (0,0)\n",
    "    \n",
    "    for i, val in enumerate(column):\n",
    "        if i != len(column)-1:\n",
    "            avg = (val + column.iloc[i+1])/2\n",
    "            class1, class2 = df[column>avg], df[column<=avg]\n",
    "            informational_gain = info_gain(df, class1, class2) \n",
    "\n",
    "            if best_split[1] < informational_gain:\n",
    "                best_split = (avg, informational_gain)\n",
    "\n",
    "    return best_split\n",
    "\n",
    "def best_column(df):\n",
    "    \"\"\"Iterates through all columns of df except the last one, \n",
    "    calculates the best_threshold of each column.\n",
    "    \n",
    "    Returns: \n",
    "    (threshold, info_gain, col_name) of the column with the best info gain.\n",
    "    \"\"\"\n",
    "\n",
    "    best_split = (0, 0, \"\")\n",
    "    \n",
    "    # Iterate through all columns except the last one\n",
    "    for col_name in df.columns[:-1]:\n",
    "        threshold, info_gain = best_threshold(df[col_name], df)\n",
    "        if best_split[1] < info_gain:\n",
    "            best_split = threshold, info_gain, col_name\n",
    "            \n",
    "    return best_split  # (threshold, info_gain, col_name)\n",
    "\n",
    "# print(best_column(iris_df))\n",
    "\n",
    "def split_df(df):\n",
    "    \n",
    "    threshold, info_gain, best_col = best_column(df)\n",
    "    \n",
    "    left_df = df[df[best_col]>threshold]\n",
    "    right_df = df[df[best_col]<=threshold]\n",
    "    \n",
    "    return threshold, info_gain, best_col, left_df, right_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd523803",
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing\n",
    "# print(\"best threshold for the petal_width feature \\n\", best_threshold(iris_df[\"petal_width\"], iris_df),\"\\n\")\n",
    "# print(\"best threshold for the petal_length feature \\n\", best_threshold(iris_df[\"petal_length\"], iris_df),\"\\n\")\n",
    "# print(\"best threshold for the sepal_length feature \\n\",best_threshold(iris_df[\"sepal_length\"], iris_df),\"\\n\")\n",
    "# print(\"best threshold for the sepal_width feature \\n\",best_threshold(iris_df[\"sepal_width\"], iris_df),\"\\n\")\n",
    "# print(\"\\n Best first split of the dataset: \\n\")\n",
    "# print(split_df(iris_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae602028",
   "metadata": {},
   "source": [
    "# DECISION TREE BUILDING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b079cc",
   "metadata": {},
   "source": [
    "## node class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89efa0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTreeNode:\n",
    "    def __init__(self, feature=None, threshold=None, left=None, right=None, depth=None, info_gain=None, leaf=None, df = None):\n",
    "        self.feature = feature \n",
    "        self.threshold = threshold\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.leaf = leaf\n",
    "        self.depth = depth\n",
    "        self.info_gain = info_gain\n",
    "        self.df = df \n",
    "\n",
    "    def __str__(self):\n",
    "        node_representation = \"\"\n",
    "        if self.leaf is not None:\n",
    "            node_representation = f\"Node Depth: {self.depth}, Leaf: {self.leaf}, Df: {self.df}\"\n",
    "        else:\n",
    "            left_child = \"Present\" if self.left else \"None\"\n",
    "            right_child = \"Present\" if self.right else \"None\"\n",
    "            node_representation = (f\"Node Depth: {self.depth}\\n\"\n",
    "                                   f\"Feature: {self.feature}\\n\"\n",
    "                                   f\"Threshold: {self.threshold}\\n\"\n",
    "                                   f\"Information Gain: {self.info_gain}\\n\"\n",
    "                                   f\"Dataset used: {self.df}\\n\")\n",
    "\n",
    "        return node_representation + \"\\n\" \n",
    "\n",
    "def build_tree(df, min_sample_size, depth=0, max_depth=100):\n",
    "    if len(df) <= min_sample_size or depth >= max_depth or len(np.unique(df.iloc[:,-1])) == 1:\n",
    "        \n",
    "        leaf_value = df.iloc[:,-1].mode()[0]\n",
    "        return DecisionTreeNode(depth = depth, leaf=leaf_value, df=df)\n",
    "\n",
    "    threshold, info_gain, best_col, df_left, df_right = split_df(df)\n",
    "    \n",
    "#     print(df_left, \"\\n length:\", len(df_left))\n",
    "#     print(df_right, \"\\n length:\", len(df_right))\n",
    "    \n",
    "    left_node = build_tree(df_left, min_sample_size, depth + 1)\n",
    "    right_node = build_tree(df_right,min_sample_size, depth + 1)\n",
    "\n",
    "    return DecisionTreeNode(feature=best_col, threshold=threshold,left=left_node, right=right_node, depth = depth, info_gain = info_gain,leaf = None, df=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e749c7f",
   "metadata": {},
   "source": [
    "# TESTING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0212c349",
   "metadata": {},
   "source": [
    "## predict and find accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2393c749",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df, test_df = train_test_split(iris_df, test_size=0.2, random_state=15) \n",
    "# # tree = build_tree(df=train_df, min_sample_size =23)\n",
    "\n",
    "def predict_all(tree_root, test_df):\n",
    "    def traverse(tree_node, x):\n",
    "        if tree_node.leaf is not None:\n",
    "            return tree_node.leaf\n",
    "\n",
    "        threshold, feature = tree_node.threshold, tree_node.feature\n",
    "        \n",
    "        if x[feature] > threshold:\n",
    "            return traverse(tree_node.left, x)\n",
    "        else:\n",
    "            return traverse(tree_node.right, x)\n",
    "    \n",
    "    \n",
    "    predicted_list = []\n",
    "    for _, x in test_df.iterrows():\n",
    "        pred_x = traverse(tree_root, x)\n",
    "        predicted_list.append(pred_x)\n",
    "        \n",
    "    return predicted_list\n",
    "\n",
    "# print(predict_all(tree, test_df))\n",
    "# print(test_df.iloc[:,-1])\n",
    "# print(accuracy_score(test_df.iloc[:,-1],predict_all(tree, test_df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfdbefb1",
   "metadata": {},
   "source": [
    "### accuracy and accuracy scores for a particular n_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75a705f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy scores for 10th fold are [0.9282608695652174, 0.9347826086956522, 0.9282608695652174, 0.9152173913043479, 0.9043478260869565, 0.9217391304347826, 0.9195652173913044, 0.9478260869565217, 0.9326086956521739, 0.9152173913043479]\n",
      "Average Accuracy: 0.9247826086956522\n",
      "Standard Deviation: 0.011633989704573593\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def cross_validate(data, k=10):\n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=15)\n",
    "    \n",
    "    accuracy_scores = []\n",
    "\n",
    "    for train_index, test_index in kf.split(data):\n",
    "        train_df, test_df = data.iloc[train_index], data.iloc[test_index]\n",
    "        \n",
    "        tree = build_tree(df=train_df, min_sample_size=5)\n",
    "        predictions = predict_all(tree, test_df)\n",
    "        \n",
    "        accuracy = accuracy_score(test_df.iloc[:,-1], predictions)\n",
    "        accuracy_scores.append(accuracy)\n",
    "\n",
    "    return k, accuracy_scores, np.mean(accuracy_scores), np.std(accuracy_scores)\n",
    "\n",
    "k, accuracy_scores, mean_accuracy, std_dev = cross_validate(iris_df)\n",
    "print(f\"Accuracy scores for {k}th fold are {accuracy_scores}\")\n",
    "print(\"Average Accuracy:\", mean_accuracy)\n",
    "print(\"Standard Deviation:\", std_dev)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2122ca",
   "metadata": {},
   "source": [
    "## predict for different n_min for spambase\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9229edc5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy scores for 10th fold are [0.9478260869565217, 0.9108695652173913, 0.9326086956521739, 0.9347826086956522, 0.9326086956521739, 0.9260869565217391, 0.9347826086956522, 0.9478260869565217, 0.9326086956521739, 0.908695652173913]\n",
      "Average Accuracy: 0.9308695652173913\n",
      "Standard Deviation: 0.012366489263763387\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def cross_validate_n_min(df, n_min, k=10):\n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=10)\n",
    "    \n",
    "    accuracy_scores = []\n",
    "\n",
    "    for train_index, test_index in kf.split(df):\n",
    "        train_df, test_df = df.iloc[train_index], df.iloc[test_index]\n",
    "        \n",
    "        tree = build_tree(df = train_df, min_sample_size = n_min)\n",
    "        predictions = predict_all(tree, test_df)\n",
    "        \n",
    "        accuracy = accuracy_score(test_df.iloc[:,-1], predictions)\n",
    "        accuracy_scores.append(accuracy)\n",
    "\n",
    "    return k, accuracy_scores, np.mean(accuracy_scores), np.std(accuracy_scores)\n",
    "\n",
    "k, accuracy_scores, mean_accuracy, std_dev = cross_validate_n_min(iris_df,n_min=10)\n",
    "print(f\"Accuracy scores for {k}th fold are {accuracy_scores}\")\n",
    "print(\"Average Accuracy:\", mean_accuracy)\n",
    "print(\"Standard Deviation:\", std_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a50ced67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       mean_accuracy   std_dev  \\\n",
      "n_min                            \n",
      "230         0.903261  0.009637   \n",
      "460         0.890870  0.017359   \n",
      "690         0.880000  0.024591   \n",
      "920         0.838913  0.022685   \n",
      "\n",
      "                                         accuracy_scores  \n",
      "n_min                                                     \n",
      "230    [0.9130434782608695, 0.8891304347826087, 0.891...  \n",
      "460    [0.8978260869565218, 0.8717391304347826, 0.860...  \n",
      "690    [0.8891304347826087, 0.8717391304347826, 0.852...  \n",
      "920    [0.8282608695652174, 0.8717391304347826, 0.852...  \n"
     ]
    }
   ],
   "source": [
    "n_mins = [230,460,690,920]\n",
    "summary = []\n",
    "\n",
    "for n_min in n_mins:\n",
    "    k, accuracy_scores, mean_accuracy, std_dev = cross_validate_n_min(df=iris_df, n_min=n_min)\n",
    "    summary.append({\n",
    "        'n_min': n_min,\n",
    "        'mean_accuracy': mean_accuracy,\n",
    "        'std_dev': std_dev,\n",
    "        'accuracy_scores': accuracy_scores\n",
    "    })\n",
    "\n",
    "summary_df = pd.DataFrame(summary)\n",
    "summary_df.set_index('n_min', inplace=True)\n",
    "print(summary_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15d8d59",
   "metadata": {},
   "source": [
    "## predict for different n_min for iris dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92862a79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       mean_accuracy   std_dev  \\\n",
      "n_min                            \n",
      "5           0.960000  0.061101   \n",
      "10          0.966667  0.061464   \n",
      "15          0.966667  0.061464   \n",
      "20          0.966667  0.061464   \n",
      "\n",
      "                                         accuracy_scores  \n",
      "n_min                                                     \n",
      "5      [1.0, 1.0, 1.0, 0.9333333333333333, 0.8, 1.0, ...  \n",
      "10     [1.0, 1.0, 1.0, 0.9333333333333333, 0.8, 1.0, ...  \n",
      "15     [1.0, 1.0, 1.0, 0.9333333333333333, 0.8, 1.0, ...  \n",
      "20     [1.0, 1.0, 1.0, 0.9333333333333333, 0.8, 1.0, ...  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def cross_validate_n_min(df, n_min, k=10):\n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=10)\n",
    "    \n",
    "    accuracy_scores = []\n",
    "\n",
    "    for train_index, test_index in kf.split(df):\n",
    "        train_df, test_df = df.iloc[train_index], df.iloc[test_index]\n",
    "        \n",
    "        tree = build_tree(df = train_df, min_sample_size = n_min)\n",
    "        predictions = predict_all(tree, test_df)\n",
    "        \n",
    "        accuracy = accuracy_score(test_df.iloc[:,-1], predictions)\n",
    "        accuracy_scores.append(accuracy)\n",
    "\n",
    "    return k, accuracy_scores, np.mean(accuracy_scores), np.std(accuracy_scores)\n",
    "\n",
    "# k, accuracy_scores, mean_accuracy, std_dev = cross_validate_n_min(iris_df,n_min=10)\n",
    "# print(f\"Accuracy scores for {k}th fold are {accuracy_scores}\")\n",
    "# print(\"Average Accuracy:\", mean_accuracy)\n",
    "# print(\"Standard Deviation:\", std_dev)\n",
    "\n",
    "n_mins = [5,10,15,20]\n",
    "\n",
    "summary = []\n",
    "\n",
    "for n_min in n_mins:\n",
    "    k, accuracy_scores, mean_accuracy, std_dev = cross_validate_n_min(df=real_iris_df, n_min=n_min)\n",
    "    summary.append({\n",
    "        'n_min': n_min,\n",
    "        'mean_accuracy': mean_accuracy,\n",
    "        'std_dev': std_dev,\n",
    "        'accuracy_scores': accuracy_scores\n",
    "    })\n",
    "\n",
    "summary_df = pd.DataFrame(summary)\n",
    "summary_df.set_index('n_min', inplace=True)\n",
    "print(summary_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
